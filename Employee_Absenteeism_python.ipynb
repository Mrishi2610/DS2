{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from fancyimpute import KNN\n",
    "\n",
    "#Libraries for plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting working directory\n",
    "os.chdir(\"C:/Users/Rishabh/Desktop/All/edwisor/Project2\")\n",
    "\n",
    "# Loading data\n",
    "emp_absent = pd.read_excel(\"Absenteeism_at_work.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_absent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 rows of data\n",
    "emp_absent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Types of all the variables\n",
    "emp_absent.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Unique values present in each variable\n",
    "emp_absent.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data types\n",
    "emp_absent['ID'] = emp_absent['ID'].astype('category')\n",
    "\n",
    "emp_absent['Reason for absence'] = emp_absent['Reason for absence'].replace(0,20)\n",
    "emp_absent['Reason for absence'] = emp_absent['Reason for absence'].astype('category')\n",
    "\n",
    "emp_absent['Month of absence'] = emp_absent['Month of absence'].replace(0,np.nan)\n",
    "emp_absent['Month of absence'] = emp_absent['Month of absence'].astype('category')\n",
    "\n",
    "emp_absent['Day of the week'] = emp_absent['Day of the week'].astype('category')\n",
    "emp_absent['Seasons'] = emp_absent['Seasons'].astype('category')\n",
    "emp_absent['Disciplinary failure'] = emp_absent['Disciplinary failure'].astype('category')\n",
    "emp_absent['Education'] = emp_absent['Education'].astype('category')\n",
    "emp_absent['Son'] = emp_absent['Son'].astype('category')\n",
    "emp_absent['Social drinker'] = emp_absent['Social drinker'].astype('category')\n",
    "emp_absent['Social smoker'] = emp_absent['Social smoker'].astype('category')\n",
    "emp_absent['Pet'] = emp_absent['Pet'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy of dataframe\n",
    "df = emp_absent.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorising variables into \" Continuos\" and \"Categorical\"\n",
    "continuous_vars = ['Distance from Residence to Work', 'Service time', 'Age', 'Work load Average/day ', 'Transportation expense',\n",
    "       'Hit target', 'Weight', 'Height', 'Body mass index', 'Absenteeism time in hours']\n",
    "\n",
    "categorical_vars = ['ID','Reason for absence','Month of absence','Day of the week',\n",
    "                     'Seasons','Disciplinary failure', 'Education', 'Social drinker',\n",
    "                     'Social smoker', 'Pet', 'Son']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe with number of missing values\n",
    "missing_val = pd.DataFrame(df.isnull().sum())\n",
    "\n",
    "#Getting row names as columns\n",
    "missing_val = missing_val.reset_index()\n",
    "\n",
    "#Renaming columns\n",
    "missing_val = missing_val.rename(columns = {'index': 'Variables', 0: 'Missing_perc'})\n",
    "missing_val\n",
    "\n",
    "#Missing value percentage\n",
    "missing_val['Missing_perc'] = (missing_val['Missing_perc']/len(df))*100\n",
    "\n",
    "#Sorting rows as per missing percentage\n",
    "missing_val = missing_val.sort_values('Missing_perc', ascending = False).reset_index(drop = True)\n",
    "missing_val.to_csv(\"Missing_perc.csv\", index = False)\n",
    "\n",
    "missing_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual value = 29\n",
    "#Mean = 26.68\n",
    "#Median = 25\n",
    "#KNN = 29\n",
    "print(df['Body mass index'].iloc[1])\n",
    "\n",
    "#Set the value of first row in Body mass index as NAN\n",
    "#create missing value\n",
    "df['Body mass index'].iloc[1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Imputation\n",
    "#df['Body mass index'] = df['Body mass index'].fillna(df['Body mass index'].mean())\n",
    "\n",
    "#Median Imputation\n",
    "#df['Body mass index'] = df['Body mass index'].fillna(df['Body mass index'].median())\n",
    "\n",
    "#KNN Imputation\n",
    "df = pd.DataFrame(KNN(k = 3).fit_transform(df), columns = df.columns)\n",
    "df['Body mass index'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cCategorical values rounding\n",
    "for i in categorical_vars:\n",
    "    df.loc[:,i] = df.loc[:,i].round()    \n",
    "    df.loc[:,i] = df.loc[:,i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rechecking missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of data using graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Bar graph of categorical Data\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.factorplot(data=df, x='Reason for absence', kind= 'count',size=4,aspect=2)\n",
    "sns.factorplot(data=df, x='Seasons', kind= 'count',size=4,aspect=2)\n",
    "sns.factorplot(data=df, x='Education', kind= 'count',size=4,aspect=2)\n",
    "sns.factorplot(data=df, x='Disciplinary failure', kind= 'count',size=4,aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of numeric data\n",
    "plt.hist(data=df, x='Weight', bins='auto', label='Weight')\n",
    "plt.xlabel('Weight')\n",
    "plt.title(\"Weight Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking distribution of numeric data\n",
    "plt.hist(data=df, x='Age', bins='auto', label='Age')\n",
    "plt.xlabel('Age')\n",
    "plt.title(\"Age Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot to check outliers\n",
    "sns.boxplot(data=df[['Absenteeism time in hours','Body mass index','Height','Weight']])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot to check outliers\n",
    "sns.boxplot(data=df[['Hit target','Service time','Age','Transportation expense']])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in continuous_vars:\n",
    "    q75, q25 = np.percentile(df[i], [75,25])\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    # Calculating upper-ex and lower-ex\n",
    "    minimum = q25 - (iqr*1.5)\n",
    "    maximum = q75 + (iqr*1.5)\n",
    "    \n",
    "    # Replacing all the outliers with NA\n",
    "    df.loc[df[i]< minimum,i] = np.nan\n",
    "    df.loc[df[i]> maximum,i] = np.nan\n",
    "\n",
    "\n",
    "# Impute NA's with KNN\n",
    "df = pd.DataFrame(KNN(k = 3).fit_transform(df), columns = df.columns)\n",
    "# Rechecking missing value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot to check outliers\n",
    "sns.boxplot(data=df[['Absenteeism time in hours','Body mass index','Height','Weight']])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot to check outliers\n",
    "sns.boxplot(data=df[['Hit target','Service time','Age','Transportation expense']])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting continuous variables\n",
    "df_corr = df.loc[:,continuous_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multicollinearity test\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "#Generating correlation matrix\n",
    "corr = df_corr.corr()\n",
    "\n",
    "#Plot matrix\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), \n",
    "            cmap=sns.diverging_palette(220, 50, as_cmap=True),\n",
    "            square=True, ax=ax, annot = True)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable Reduction\n",
    "to_drop = ['Weight']\n",
    "df = df.drop(to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the dataset\n",
    "continuous_vars.remove('Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy of clean data\n",
    "clean_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality check\n",
    "for i in continuous_vars:\n",
    "    if i == 'Absenteeism time in hours':\n",
    "        continue\n",
    "    sns.distplot(df[i],bins = 'auto')\n",
    "    plt.title(\"Checking Distribution for Variable \"+str(i))\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing continuous variables\n",
    "for i in continuous_vars:\n",
    "    if i == 'Absenteeism time in hours':\n",
    "        continue\n",
    "    df[i] = (df[i] - df[i].min())/(df[i].max()-df[i].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy variables of categorical variables\n",
    "df = pd.get_dummies(data = df, columns = categorical_vars)\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( df.iloc[:, df.columns != 'Absenteeism time in hours'], df.iloc[:, 8], test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting target variable\n",
    "target = df['Absenteeism time in hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required library for PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Converting data to numpy\n",
    "X = df.values\n",
    "pca = PCA(n_components=115)\n",
    "pca.fit(X)\n",
    "\n",
    "#Variance proportion\n",
    "var= pca.explained_variance_ratio_\n",
    "\n",
    "#Scree plot\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "#Plotting\n",
    "plt.plot(var1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting 45 components (95+% data explainatory)\n",
    "pca = PCA(n_components=45)\n",
    "pca.fit(X)\n",
    "\n",
    "#Splitting data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,target, test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "#RMSE: 0.0353\n",
    "#R-squared: 0.9998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Decision tree model\n",
    "dt_model = DecisionTreeRegressor(random_state = 1).fit(X_train,y_train)\n",
    "\n",
    "#Perdicting for test\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "#Creating data frame for actual and predicted values\n",
    "df_dt = pd.DataFrame({'actual': y_test, 'pred': dt_predictions})\n",
    "print(df_dt.head())\n",
    "\n",
    "#Calculating RMSE and R-squared value\n",
    "print(\"Root Mean Squared Error: \"+str(RMSE(y_test, dt_predictions)))\n",
    "print(\"R^2 Score(coefficient of determination) = \"+str(r2_score(y_test, dt_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "#RMSE: 0.04453\n",
    "#R-squared: 0.9998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Random forest model\n",
    "rf_model = RandomForestRegressor(n_estimators = 500, random_state = 1).fit(X_train,y_train)\n",
    "\n",
    "#Perdicting for test \n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "#Creating data frame for actual and predicted values\n",
    "df_rf = pd.DataFrame({'actual': y_test, 'pred': rf_predictions})\n",
    "print(df_rf.head())\n",
    "\n",
    "#Calculating RMSE and R-squared value\n",
    "print(\"Root Mean Squared Error: \"+str(RMSE(y_test, rf_predictions)))\n",
    "print(\"R^2 Score(coefficient of determination) = \"+str(r2_score(y_test, rf_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "#RMSE: 0.0013\n",
    "#R-squared: 0.9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Training the model\n",
    "lr_model = LinearRegression().fit(X_train , y_train)\n",
    "\n",
    "#Perdicting for test\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "#Creating data frame for actual and predicted values\n",
    "df_lr = pd.DataFrame({'actual': y_test, 'pred': lr_predictions})\n",
    "print(df_lr.head())\n",
    "\n",
    "#Calculating RMSE and R-squared value\n",
    "print(\"Root Mean Squared Error: \"+str(RMSE(y_test, lr_predictions)))\n",
    "print(\"R^2 Score(coefficient of determination) = \"+str(r2_score(y_test, lr_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
